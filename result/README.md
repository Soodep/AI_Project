**Test1:**
batch_size=128, epochs=100, learning_rate=0.05, wt_decay=1e-5, Optimizer = SGD

**Test2:**
batch_size=128, epochs=200, learning_rate=0.05, wt_decay=1e-5, Optimizer = SGD

**Test3:**
batch_size=128, epochs=200, learning_rate=0.05, wt_decay=1e-5, Optimizer = Adam

**Test4:**
batch_size=128, epochs=100, learning_rate=0.05, wt_decay=1e-5, Optimizer = Adam
